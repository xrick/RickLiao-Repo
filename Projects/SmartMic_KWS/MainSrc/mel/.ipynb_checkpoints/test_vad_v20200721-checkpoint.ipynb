{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as numpy\n",
    "import scipy.io as spio\n",
    "import scipy.io.wavfile as sciwav\n",
    "import os.path as path\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import os\n",
    "import timeit as tt\n",
    "import json\n",
    "import sys\n",
    "#import pandas\n",
    "from tqdm import tqdm\n",
    "import csv\n",
    "from datetime import date\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pyAudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFilesInFloder(folderPath):\n",
    "    onlyfiles = [f for f in listdir(folderPath) if isfile(join(folderPath, f)) \n",
    "                 and f.endswith(\"wav\")]\n",
    "    return onlyfiles\n",
    "\n",
    "def getDirsInFolder(baseDirPath):\n",
    "    onlySubDirs = [d for d in listdir(baseDirPath) if isdir(join(baseDirPath, d))]\n",
    "    return onlySubDirs\n",
    "\n",
    "def safe_wav_read(wav_file):\n",
    "    try:\n",
    "        std_sr = 16000\n",
    "        sr, sig = wavio.read(wav_file)\n",
    "        if sig.shape[0] < sig.size:\n",
    "            sig = sig[0]\n",
    "            print(\"\\n{} is channel 2\".format(wav_file))\n",
    "        return sr, sig\n",
    "    except:\n",
    "        print(\"Error occured in read and convert wav to ndarray in file {}\".format(wav_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_filterbanks(nfilt=10,nfft=1024,samplerate=16000,lowfreq=0,highfreq=8000):\n",
    "#     highfreq= highfreq or samplerate/2\n",
    "#     assert highfreq <= samplerate/2, \"highfreq is greater than samplerate/2\"\n",
    "#     # compute points evenly spaced in mels\n",
    "#     lowmel = hz2mel_nature(lowfreq)\n",
    "#     highmel = hz2mel_nature(highfreq)\n",
    "#     melpoints = numpy.linspace(lowmel,highmel,nfilt+2)\n",
    "#     # our points are in Hz, but we use fft bins, so we have to convert\n",
    "#     #  from Hz to fft bin number\n",
    "#     mid_freqs = mel2hz_nature(melpoints)\n",
    "    \n",
    "#     bins = numpy.floor((nfft+1)*mid_freqs/samplerate)\n",
    "#     fbank = numpy.zeros([nfilt,nfft//2+1])\n",
    "#     for j in range(0,nfilt):\n",
    "#         for i in range(int(bins[j]), int(bins[j+1])):\n",
    "#             fbank[j,i] = (i - bins[j]) / (bins[j+1]-bins[j])\n",
    "#         for i in range(int(bins[j+1]), int(bins[j+2])):\n",
    "#             fbank[j,i] = (bins[j+2]-i) / (bins[j+2]-bins[j+1])\n",
    "#     print(\"Middel Frequences are {}\".format(mid_freqs))\n",
    "#     print(\"Bins are {}\".format(bins))\n",
    "#     return fbank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_filterbanks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preemphasis(signal, coeff=0.95):\n",
    "    return numpy.append(signal[0], signal[1:] - coeff * signal[:-1])\n",
    "\n",
    "def hz2mel_nature(freq):\n",
    "    return 1127. * numpy.log(1. + freq / 700.)\n",
    "\n",
    "def mel2hz_nature(mel):\n",
    "    return 700. * (numpy.exp(mel / 1127.) - 1.)\n",
    "\n",
    "def hz2mel(hz):\n",
    "    return 2595 * numpy.log10(1+hz/700.)\n",
    "\n",
    "def mel2hz(mel):\n",
    "    return 700*(10**(mel/2595.0)-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# midfreq_array = numpy.array([16, 20, 26, 36, 48, 60, 80, 101, 256, 353])\n",
    "# mel2hz_nature(midfreq_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filterbanks_from_40(nfilt=40,nfft=1024,samplerate=16000,lowfreq=70,highfreq=8000):\n",
    "    highfreq= highfreq or samplerate/2\n",
    "    assert highfreq <= samplerate/2, \"highfreq is greater than samplerate/2\"\n",
    "\n",
    "    # compute points evenly spaced in mels\n",
    "    lowmel = hz2mel_nature(lowfreq)\n",
    "    highmel = hz2mel_nature(highfreq)\n",
    "    \n",
    "    melpoints = numpy.linspace(lowmel,highmel,nfilt+2)\n",
    "    mid_freqs = mel2hz_nature(melpoints)\n",
    "#*********************************************\n",
    "    c = 0\n",
    "    for freq in mid_freqs:\n",
    "        print(\"{}-{}\".format(\"get_filterbanks_from_40\",freq))\n",
    "        c += 1 \n",
    "    target_mid_freqs = numpy.empty(12,dtype=numpy.float)\n",
    "    idx = 0\n",
    "    for i in (2,3,5,6,8,9,10,12,22,32):\n",
    "        print(mid_freqs[i])\n",
    "        target_mid_freqs[idx] = mid_freqs[i]\n",
    "        idx += 1\n",
    "    nfilt = 10\n",
    "#*********************************************\n",
    "    bin = numpy.floor((nfft+1)*target_mid_freqs/samplerate)\n",
    "    fbank = numpy.zeros([nfilt,nfft//2+1])\n",
    "    for j in range(0,nfilt):\n",
    "        for i in range(int(bin[j]), int(bin[j+1])):\n",
    "            fbank[j,i] = (i - bin[j]) / (bin[j+1]-bin[j])\n",
    "        for i in range(int(bin[j+1]), int(bin[j+2])):\n",
    "            fbank[j,i] = (bin[j+2]-i) / (bin[j+2]-bin[j+1])\n",
    "    return fbank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filterbank_from_midfreqs(midFreqs,samplerate, n_filt, n_fft):\n",
    "#     mid_freqs = midFreqs#[229.8,304.1,402.4,532.4,704.4,931.9,1233.1,1631.5,4000.,5500.]\n",
    "    target_mid_freqs = numpy.empty(n_filt+2,dtype=numpy.float)\n",
    "    idx = 0\n",
    "    for freq in midFreqs:\n",
    "        target_mid_freqs[idx] = freq\n",
    "        idx += 1\n",
    "#     target_mid_freqs[n_filt]=0.0\n",
    "#     target_mid_freqs[n_filt+1]=0.0\n",
    "    print(target_mid_freqs)\n",
    "    bins = numpy.floor((n_fft+1)*target_mid_freqs/samplerate)\n",
    "    print(len(bins))\n",
    "    fbank = numpy.zeros([n_filt,n_fft//2+1])\n",
    "    for j in range(0,n_filt):\n",
    "        for i in range(int(bins[j]), int(bins[j+1])):\n",
    "            fbank[j,i] = (i - bins[j]) / (bins[j+1]-bins[j])\n",
    "        for i in range(int(bins[j+1]), int(bins[j+2])):\n",
    "            fbank[j,i] = (bins[j+2]-i) / (bins[j+2]-bins[j+1])\n",
    "    return fbank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filterbanks(nfilt=10,nfft=1024,samplerate=16000,lowfreq=0,highfreq=8000):\n",
    "    highfreq= highfreq or samplerate/2\n",
    "    \"\"\"Compute log Mel-filterbank energy features from an audio signal.\n",
    "    :param signal: the audio signal from which to compute features. Should be an N*1 array\n",
    "    :param samplerate: the sample rate of the signal we are working with, in Hz.\n",
    "    :param winlen: the length of the analysis window in seconds. Default is 0.025s (25 milliseconds)\n",
    "    :param winstep: the step between successive windows in seconds. Default is 0.01s (10 milliseconds)\n",
    "    :param nfilt: the number of filters in the filterbank, default 26.\n",
    "    :param nfft: the FFT size. Default is 512.\n",
    "    :param lowfreq: lowest band edge of mel filters. In Hz, default is 0.\n",
    "    :param highfreq: highest band edge of mel filters. In Hz, default is samplerate/2\n",
    "    :param preemph: apply preemphasis filter with preemph as coefficient. 0 is no filter. Default is 0.97.\n",
    "    :param winfunc: the analysis window to apply to each frame. By default no window is applied. You can use numpy window functions here e.g. winfunc=numpy.hamming\n",
    "    :returns: A numpy array of size (NUMFRAMES by nfilt) containing features. Each row holds 1 feature vector.\n",
    "    \"\"\"\n",
    "    assert highfreq <= samplerate/2, \"highfreq is greater than samplerate/2\"\n",
    "    # compute points evenly spaced in mels\n",
    "    lowmel = hz2mel_nature(lowfreq)\n",
    "    highmel = hz2mel_nature(highfreq)\n",
    "    melpoints = numpy.linspace(lowmel,highmel,nfilt+2)\n",
    "    # our points are in Hz, but we use fft bins, so we have to convert\n",
    "    #  from Hz to fft bin number\n",
    "    mid_freqs = mel2hz_nature(melpoints)\n",
    "    \n",
    "    bins = numpy.floor((nfft+1)*mid_freqs/samplerate)\n",
    "    fbank = numpy.zeros([nfilt,nfft//2+1])\n",
    "    for j in range(0,nfilt):\n",
    "        for i in range(int(bins[j]), int(bins[j+1])):\n",
    "            fbank[j,i] = (i - bins[j]) / (bins[j+1]-bins[j])\n",
    "        for i in range(int(bins[j+1]), int(bins[j+2])):\n",
    "            fbank[j,i] = (bins[j+2]-i) / (bins[j+2]-bins[j+1])\n",
    "    print(\"Middel Frequences are {}\".format(mid_freqs))\n",
    "    print(\"Bins are {}\".format(bins))\n",
    "    return fbank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loss_softmax_cross = label * (-1) * log(softmax_logits) + (1 — label) * (-1) * log(1 — softmax_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(X):\n",
    "    return 1/(1+numpy.exp(-X))\n",
    "\n",
    "def relu(X):\n",
    "    return numpy.maximum(0,X)\n",
    "\n",
    "def softmax(X):\n",
    "    expo = numpy.exp(X)\n",
    "    expo_sum = numpy.sum(numpy.exp(X))\n",
    "    return expo/expo_sum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def magspec(frames, NFFT):\n",
    "    if numpy.shape(frames)[1] > NFFT:\n",
    "        logging.warn(\n",
    "            'frame length (%d) is greater than FFT size (%d), frame will be truncated. Increase NFFT to avoid.',\n",
    "            numpy.shape(frames)[1], NFFT)\n",
    "    complex_spec = numpy.fft.fft(frames, NFFT)\n",
    "#     complex_spec = numpy.fft.rfft(frames, NFFT)\n",
    "    return numpy.absolute(complex_spec)\n",
    "\n",
    "def powspec(frames, NFFT):\n",
    "    theFrames = magspec(frames,NFFT)\n",
    "    return numpy.square(theFrames)\n",
    "#     return 1.0 / NFFT * numpy.square(theFrames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8.])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy.square(numpy.absolute([2-2j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n// input_test[] = raw data\\n\\n\\nvoid buffer_trans()\\n{\\n\\tint i,tmp_index;\\n\\tlocal_power=0;\\n\\tfor (i = 0; i < fft_frame_size; i++){\\n\\t\\ttmp_index = i*2;\\n\\t\\tinput[tmp_index] = input_test[i];\\n\\t\\tinput[tmp_index+1] = 0;\\n\\t\\tlocal_power = local_power + (input_test[i]*input_test[i]);\\n\\t}\\n\\tlocal_power = sqrt(local_power);\\n\\tfor (i = fft_frame_size*2; i < fft_order*2; i++)  {\\n\\t\\tinput[i] = 0;//zero padding\\n\\t}\\n}\\n'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "// input_test[] = raw data\n",
    "\n",
    "\n",
    "void buffer_trans()\n",
    "{\n",
    "\tint i,tmp_index;\n",
    "\tlocal_power=0;\n",
    "\tfor (i = 0; i < fft_frame_size; i++){\n",
    "\t\ttmp_index = i*2;\n",
    "\t\tinput[tmp_index] = input_test[i];\n",
    "\t\tinput[tmp_index+1] = 0;\n",
    "\t\tlocal_power = local_power + (input_test[i]*input_test[i]);\n",
    "\t}\n",
    "\tlocal_power = sqrt(local_power);\n",
    "\tfor (i = fft_frame_size*2; i < fft_order*2; i++)  {\n",
    "\t\tinput[i] = 0;//zero padding\n",
    "\t}\n",
    "}\n",
    "\"\"\"\n",
    "# def get_local_power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_ms = 25\n",
    "overlap_factor = 0.75\n",
    "frames_per_segment = 4\n",
    "num_fft = 1024\n",
    "def runAccuracyTest(weights=None, wav_file=None, comp_base=1, threshold=-145,\n",
    "                    filter_bank=None ,startPoint=1600, stepQuantity=400, record_csv=None):\n",
    "    w1 = weights[\"w1\"]\n",
    "    w2 = weights[\"w2\"]\n",
    "    w3 = weights[\"w3\"]\n",
    "    b1 = weights[\"b1\"]\n",
    "    b2 = weights[\"b2\"]\n",
    "    b3 = weights[\"b3\"]\n",
    "    \n",
    "    fs, sig = sciwav.read(wav_file)\n",
    "#     print(sig.shape)\n",
    "    if sig.shape[0] < sig.size:\n",
    "        sig = sig.T[0]\n",
    "    \n",
    "    count_answer_1 = 0\n",
    "    count_answer_0 = 0\n",
    "    count_test_1 = 0\n",
    "    count_test_0 = 0\n",
    "\n",
    "    y_answer = numpy.empty([0,0],dtype=int)\n",
    "    y_test = numpy.empty([0,0])\n",
    "        \n",
    "    tmp_data_list = []\n",
    "    tmp_lbl_list = []\n",
    "    data_length = len(sig)\n",
    "    frame_size = int(fs * frame_ms // 1000)\n",
    "    hop_step = int(frame_size - (frame_size*overlap_factor)) #for old overlap\n",
    "    segment_size = int(frame_size * frames_per_segment)\n",
    "    segment_overlap = int(segment_size * overlap_factor)\n",
    "    segment_step = int(segment_size - segment_overlap)\n",
    "    data_length = int(segment_step*(numpy.floor(data_length/segment_step)))+1\n",
    "    sample_len = 513\n",
    "    test_counter = 0\n",
    "    csv_columns = ['test_no','time_sec','prediction','answer','is_speech','is_nonspeech','energy']\n",
    "    csv_raw_list = []\n",
    "    for i in range(segment_size, data_length, segment_step):\n",
    "        \n",
    "        test_counter += 1\n",
    "        seg_2_sec = (test_counter*25)/1000\n",
    "        record_dict = {}\n",
    "        record_dict['test_no'] = test_counter\n",
    "        record_dict['time_sec']= seg_2_sec\n",
    "        idx1 = i-1600\n",
    "        idx2 = i-1200\n",
    "        idx3 = i-800\n",
    "        idx4 = i-400\n",
    "        \n",
    "        s1 = sig[idx1:idx2] #0-399\n",
    "        s2 = sig[idx2:idx3] #400-799run_test_main,number\n",
    "        s3 = sig[idx3:idx4] #800-1199\n",
    "        s4 = sig[idx4:i]    #1200-1599\n",
    "        \n",
    "#         s1 = s1*numpy.hanning(len(s1))\n",
    "#         s2 = s2*numpy.hanning(len(s2))\n",
    "#         s3 = s3*numpy.hanning(len(s3))\n",
    "#         s4 = s4*numpy.hanning(len(s4))\n",
    "        \n",
    "        s1 = s1.reshape(1,len(s1))\n",
    "        s2 = s2.reshape(1,len(s2))\n",
    "        s3 = s3.reshape(1,len(s3))\n",
    "        s4 = s4.reshape(1,len(s4))\n",
    "        \n",
    "        s1 = powspec(s1,num_fft)\n",
    "        s2 = powspec(s2,num_fft)\n",
    "        s3 = powspec(s3,num_fft)\n",
    "        s4 = powspec(s4,num_fft)\n",
    "        \n",
    "        s1 = numpy.split(s1.T,[0,sample_len],axis=0)[1]\n",
    "        s2 = numpy.split(s2.T,[0,sample_len],axis=0)[1]\n",
    "        s3 = numpy.split(s3.T,[0,sample_len],axis=0)[1]\n",
    "        s4 = numpy.split(s4.T,[0,sample_len],axis=0)[1]\n",
    "#         print(\"s1 is {}\".format(s1))\n",
    "#         return\n",
    "#         feat1 = numpy.dot(s1,aFBank.T) # compute the filterbank energies\n",
    "        feat1  = numpy.matmul(aFBank,s1)\n",
    "        feat1 = numpy.where(feat1 == 0,numpy.finfo(float).eps,feat1) # if feat is\n",
    "        feat1 = numpy.log(feat1)\n",
    "#         feat1 = 10 * numpy.log10(feat1)\n",
    "        \n",
    "#         feat2 = numpy.dot(s2,aFBank.T) # compute the filterbank energies\n",
    "        feat2  = numpy.matmul(aFBank,s2)\n",
    "        feat2 = numpy.where(feat2 == 0,numpy.finfo(float).eps,feat2) # if feat is \n",
    "        feat2 = numpy.log(feat2)\n",
    "#         feat2 = 10 * numpy.log10(feat2)\n",
    "        \n",
    "#         feat3 = numpy.dot(s3,aFBank.T) # compute the filterbank energies\n",
    "        feat3  = numpy.matmul(aFBank,s3)\n",
    "        feat3 = numpy.where(feat3 == 0,numpy.finfo(float).eps,feat3) # if feat is \n",
    "        feat3 = numpy.log(feat3)\n",
    "#         feat3 = 10 * numpy.log10(feat3)\n",
    "        \n",
    "#         feat4 = numpy.dot(s4,aFBank.T) # compute the filterbank energies\n",
    "        feat4  = numpy.matmul(aFBank,s4)\n",
    "        feat4 = numpy.where(feat4 == 0,numpy.finfo(float).eps,feat4) # if feat is \n",
    "        feat4 = numpy.log(feat4)\n",
    "#         feat4 = 10 * numpy.log10(feat4)\n",
    "        \n",
    "#         x= numpy.array([feat1[0],feat2[0],feat3[0],feat4[0]]).reshape(1,40)\n",
    "        x= numpy.array([feat1,feat2,feat3,feat4]).reshape(1,40)\n",
    "        x_40 = x[0:40]\n",
    "        \n",
    "        max_ele = numpy.amax(x_40,axis=1)\n",
    "        min_ele = numpy.amin(x_40,axis=1)\n",
    "        \n",
    "        # normalize\n",
    "        x_normalize = (x_40-min_ele)/(max_ele-min_ele+0.0001)\n",
    "        sum_of_x = numpy.sum(x_normalize)\n",
    "        record_dict['energy']=sum_of_x\n",
    "        #counting the test\n",
    "        #performing the model weight mulplications\n",
    "        answer = softmax(numpy.matmul(relu(numpy.matmul(relu(numpy.matmul(x_normalize,w1)+b1),w2)+b2),w3)+b3)\n",
    "        record_dict['is_speech'] = answer[0,1]\n",
    "        record_dict['is_nonspeech'] = answer[0,0]\n",
    "        if sum_of_x > threshold:\n",
    "            if answer[0,0] > answer[0,1]:\n",
    "                y_test = numpy.append(y_test, 0)\n",
    "                count_test_0 = count_test_0+1\n",
    "                record_dict['prediction'] = 0\n",
    "            else:\n",
    "                y_test = numpy.append(y_test, 1)\n",
    "                count_test_1 += 1\n",
    "                record_dict['prediction'] = 1\n",
    "        else:\n",
    "            y_test = numpy.append(y_test, 0)\n",
    "            count_test_0 += 1\n",
    "            record_dict['prediction'] = 0\n",
    "            \n",
    "        #counting our answer\n",
    "        if comp_base == 1:\n",
    "            if sum_of_x > threshold:\n",
    "                y_answer = numpy.append(y_answer,1)\n",
    "                count_answer_1 = count_answer_1+1\n",
    "                record_dict['answer'] = 1\n",
    "            else:\n",
    "                y_answer = numpy.append(y_answer,0)\n",
    "                count_answer_0 += 1\n",
    "                record_dict['answer'] = 0\n",
    "        else:\n",
    "            y_answer = numpy.append(y_answer,0)\n",
    "            count_answer_0 += 1\n",
    "            record_dict['answer'] = 0\n",
    "        csv_raw_list.append(record_dict)\n",
    "        \n",
    "    acc = 0\n",
    "    LED = 0\n",
    "    wrong = numpy.empty([0,0])\n",
    "    y_answer_len = len(y_answer)    \n",
    "    y_test_len = len(y_test)\n",
    "    \n",
    "    if comp_base == 1: #if our test data is human voice\n",
    "        for c in range(y_answer_len):\n",
    "            acc += abs(y_answer[c]-y_test[c])\n",
    "\n",
    "        acc = (y_answer_len-acc)/y_answer_len\n",
    "    else:\n",
    "        acc = count_test_0/(count_test_0+count_test_1)\n",
    "    \n",
    "    with open(record_csv,\"w\") as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=csv_columns)\n",
    "        writer.writeheader()\n",
    "        for data in csv_raw_list:\n",
    "            writer.writerow(data)\n",
    "    \n",
    "    return acc #json.dumps(loop_record,cls=NumpyEncoder)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy.set_printoptions(threshold=sys.maxsize)\n",
    "def dumpFB_Array(midfreqs):\n",
    "    theFB = get_filterbank_from_midfreqs(midfreqs,16000,10,1024)\n",
    "    rows = theFB.shape[0]\n",
    "    cols = theFB.shape[1]\n",
    "    with open(\"./outputfb/mel_fb_20200717.h\",\"w\")as f:\n",
    "        f.write(\"/* middle frequences:{} */\\n\".format(midfreqs))\n",
    "        f.write(\"const float fbarray[{}][{}]=\".format(rows,cols))\n",
    "        f.write(\"{\")\n",
    "        for i in range(rows):\n",
    "            f.write(\"{\")\n",
    "            for j in range(cols):\n",
    "                f.write(str(theFB[i][j]))\n",
    "                f.write(\",\")\n",
    "            f.write(\"},\")\n",
    "            f.write(\"\\n\")\n",
    "        f.write(\"}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   0.         195.0985245  251.8401972  312.1788118  376.342384\n",
      "  444.5733837  517.1296516 1550.447293  2554.078667  3461.030019\n",
      " 4620.759758  8000.       ]\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "dumpFB_Array([0.0,195.0985245,251.8401972,312.1788118,376.342384,444.5733837,517.1296516,1550.447293,2554.078667,3461.030019,4620.759758,8000.0])\n",
    "# 80/20 : 0.0,251.8,312.1,376.3,444.5,517.1,594.2,676.3,763.5,1550.4,2979.7,8000.0\n",
    "# 70/30 : 0.0,312.17,376.34,444.57,517.12,676.33,763.57,856.35,1550.44,2979.71,3212.98,8000.0\n",
    "# 60/40 : 0.0,312.17,376.34,444.57,517.12,676.33,763.57,1550.44,2979.71,3212.98,4303.57,8000.0\n",
    "# 50/50 : 0.0,312.17,376.34,444.57,517.12,676.33,1550.44,2979.71,3212.98,4303.57,5316.72,,8000.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   0.         195.0985245  251.8401972  312.1788118  376.342384\n",
      "  444.5733837  517.1296516 1550.447293  2554.078667  3461.030019\n",
      " 4620.759758  8000.       ]\n",
      "12\n",
      "aFBank shape is (10, 513)\n",
      "[   0.         195.0985245  251.8401972  312.1788118  376.342384\n",
      "  444.5733837  517.1296516 1550.447293  2554.078667  3461.030019\n",
      " 4620.759758  8000.       ]\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "#NCTU ICFILTER Middle Frequences\n",
    "# Testing need to modify two variables: __midfreqs, weight_mat_file\n",
    "# __midfreqs = [0.0,444.5,594.2,676.3,763.5,856.3,955.018,1171.497,1290.134,1416.292,1550.44,8000.0]\n",
    "__midfreqs = [0.0,195.0985245,251.8401972,312.1788118,376.342384,444.5733837,517.1296516,1550.447293,2554.078667,3461.030019,4620.759758,8000.0]\n",
    "__midfreqs_array = numpy.array(__midfreqs)\n",
    "aFBank = get_filterbank_from_midfreqs(__midfreqs_array,16000,10,1024)#[:,1:]\n",
    "print(\"aFBank shape is {}\".format(aFBank.shape))\n",
    "dumpFB_Array(__midfreqs_array)\n",
    "freq_ratio = 64\n",
    "# aFBank = get_filterbanks()\n",
    "def MultiFileTest():\n",
    "    weight_mat_file = \"../../Weights/vad_weight_128x32_20200721_00_15_50.mat\"\n",
    "    loaded_weights = spio.loadmat(weight_mat_file)\n",
    "    #get date and time string:\n",
    "    dateStr = \"{}\".format(str(date.today()).replace(\"-\", \"\"))\n",
    "    timeStr = \"{}\".format(str(datetime.now().strftime(\"%H_%M_%S\")))\n",
    "    csv_output_dir = \"./TestReports/Test_Float_32_ln_{}_freqs_{}_{}/\".format(freq_ratio,dateStr,timeStr)\n",
    "    if not path.exists(csv_output_dir):\n",
    "        os.makedirs(csv_output_dir)\n",
    "        \n",
    "    test_speech_dir = \"../Drawing/compared_wav/\"\n",
    "    test_speech_files = getFilesInFloder(test_speech_dir)\n",
    "    test_speech_acc = []\n",
    "    flistlen = len(test_speech_files)\n",
    "    for f in tqdm(test_speech_files):\n",
    "        speech_csv_file_name = csv_output_dir+\"Float32W_Test_32_ln_{}_{}_Speech_{}_{}.csv\".format(freq_ratio,f,\n",
    "                                                                                          dateStr,timeStr)\n",
    "        _acc=0\n",
    "        _acc = runAccuracyTest(loaded_weights, wav_file=test_speech_dir+f, comp_base=1, \n",
    "                                               threshold=-145, filter_bank=aFBank ,startPoint=1600, \n",
    "                                               stepQuantity=400,record_csv=speech_csv_file_name)\n",
    "        print(\"speech file {} acc value is:{}\".format(f,_acc))\n",
    "        test_speech_acc.append(_acc)\n",
    "    speech_sum_of_acc = sum(test_speech_acc)\n",
    "    speech_avg_acc = speech_sum_of_acc/flistlen\n",
    "    print(\"\\nThe average accuarncy of testing {} speech files is {}\\n\".format(flistlen,speech_avg_acc))\n",
    "    ##########################################################################\n",
    "#     test_noise_dir = \"../../TestWavFiles/Noise/20200717/\"\n",
    "#     test_noise_dir = \"../MainSrc/Drawing/raw_wav/\"\n",
    "#     test_noise_files = getFilesInFloder(test_noise_dir)\n",
    "#     test_noise_acc = []\n",
    "#     flistlen2 = len(test_noise_files)\n",
    "#     for f2 in tqdm(test_noise_files):\n",
    "#         print(\"current processing file is {}\".format(f2))\n",
    "#         noise_csv_file_name = csv_output_dir+\"Float32W_Test_32_ln_{}_{}_Noise_{}_{}.csv\".format(freq_ratio,f2,\n",
    "#                                                                                         dateStr,timeStr)\n",
    "#         _acc2= 0.\n",
    "#         _acc2 = runAccuracyTest(loaded_weights, wav_file=test_noise_dir+f2, comp_base=0, \n",
    "#                                                threshold=-145, filter_bank=aFBank ,startPoint=1600, \n",
    "#                                                stepQuantity=400,record_csv=noise_csv_file_name)\n",
    "#         print(\"noise file {} acc value is:{}\".format(f2, _acc2))\n",
    "#         test_noise_acc.append(_acc2)\n",
    "#     noise_sum_of_acc = sum(test_noise_acc)\n",
    "#     noise_avg_acc = noise_sum_of_acc/flistlen2\n",
    "#     print(\"\\nThe average accuarncy of testing {} noise files is {}\\n\".format(flistlen2,noise_avg_acc))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [00:00<00:00,  3.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "speech file 1016拍木板隔間.dat.wav acc value is:0.16624685138539042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████▋   | 2/3 [00:01<00:00,  2.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "speech file Speech_CL.mp3.wav acc value is:0.9589442815249267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:01<00:00,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "speech file Sax.dat.wav acc value is:0.0025188916876574307\n",
      "\n",
      "The average accuarncy of testing 3 speech files is 0.3759033415326582\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "MultiFileTest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def singleFileTest():\n",
    "    weight_mat_file = \"./Weights/weight_128x32_20200427_17_27_48_norm.mat\"\n",
    "    loaded_weights = spio.loadmat(weight_mat_file)\n",
    "    #get date and time string:\n",
    "    dateStr = \"{}\".format(str(date.today()).replace(\"-\", \"\"))\n",
    "    timeStr = \"{}\".format(str(datetime.now().strftime(\"%H_%M_%S\")))\n",
    "    #create csv report saving directory\n",
    "    csv_output_dir = \"./TestReports/Test_Int32_{}_{}/\".format(dateStr,timeStr)\n",
    "    if not path.exists(csv_output_dir):\n",
    "        os.makedirs(csv_output_dir)\n",
    "    #Testing Speech\n",
    "    f = \"BL.mp3.wav\"\n",
    "    test_wav = \"./TestWavFiles/Speech/\"+f   \n",
    "    cflag = 1\n",
    "    print(\"Starting VAD Test\")\n",
    "    csv_file_name = csv_output_dir+\"Int32_Test_In_MelSpec_{}_CleanSpeech_{}_{}.csv\".format(f, dateStr,timeStr)\n",
    "    ret_acc = runAccuracyTest(loaded_weights, wav_file=test_wav, comp_base=cflag, threshold=16, \n",
    "                              filter_bank=aFBank ,startPoint=1600, stepQuantity=400, \n",
    "                              record_csv=csv_file_name)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# singleFileTest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
